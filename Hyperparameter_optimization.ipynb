{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "Y-MkMbKTLICU",
    "outputId": "9b9c32cf-00b1-4bef-e28c-f1288d493ecb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "/content/drive/My Drive/Model\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# %cd ./drive/My\\ Drive/Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "colab_type": "code",
    "id": "BlJUaWqoLK2j",
    "outputId": "b9062a21-3af7-479e-d307-0c370dec4993"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' (1).ipynb_checkpoints'\t      intraday\t\t\t model.h5\n",
      " config.json\t\t\t      merged.csv\t\t model.ipynb\n",
      " core\t\t\t\t      merged_test.csv\t\t README.md\n",
      "'Hyperparameter optimization.ipynb'  'Model Documentation.pdf'\t saved_models\n"
     ]
    }
   ],
   "source": [
    "# !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 753
    },
    "colab_type": "code",
    "id": "FNupeZXOBEeI",
    "outputId": "424b1448-209d-45ba-e9d4-1688e28eb3ca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import scipy.signal as sci\n",
    "import scipy.stats as scp\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use('nbagg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from math import sqrt\n",
    "import math\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import seaborn as sns\n",
    "from core.data_processor import DataLoader\n",
    "from core.model import Model\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_22llhI6n4nb"
   },
   "source": [
    "#  **Hyper parameters to tune**\n",
    "\n",
    "\n",
    "*   No: of epocs\n",
    "*   Batch size\n",
    "*   Architecture like number of layers, neurons, dropout rate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "1wb6ZxtoN60L"
   },
   "outputs": [],
   "source": [
    "configs = json.load(open('config.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "wPnfbOIyzzUQ",
    "outputId": "6043a0b4-3c59-4096-95cb-d456330daf43"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>datetime_x</th>\n",
       "      <th>midChangeGroup</th>\n",
       "      <th>futMid</th>\n",
       "      <th>mid</th>\n",
       "      <th>arrival_rate</th>\n",
       "      <th>price</th>\n",
       "      <th>size</th>\n",
       "      <th>imbalance</th>\n",
       "      <th>Trade</th>\n",
       "      <th>spread</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-02-01 08:00:18.248</td>\n",
       "      <td>7</td>\n",
       "      <td>4839.5</td>\n",
       "      <td>1.964891</td>\n",
       "      <td>2.148942</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.876897</td>\n",
       "      <td>0</td>\n",
       "      <td>3.477824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-02-01 08:00:18.248</td>\n",
       "      <td>8</td>\n",
       "      <td>4839.5</td>\n",
       "      <td>1.978741</td>\n",
       "      <td>-0.429102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.618022</td>\n",
       "      <td>0</td>\n",
       "      <td>1.823382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-01 08:00:18.248</td>\n",
       "      <td>8</td>\n",
       "      <td>4839.5</td>\n",
       "      <td>1.978741</td>\n",
       "      <td>0.069116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.927718</td>\n",
       "      <td>0</td>\n",
       "      <td>1.823382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-02-01 08:00:18.248</td>\n",
       "      <td>8</td>\n",
       "      <td>4839.5</td>\n",
       "      <td>1.978741</td>\n",
       "      <td>0.031515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.089693</td>\n",
       "      <td>0</td>\n",
       "      <td>1.823382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-02-01 08:00:18.249</td>\n",
       "      <td>8</td>\n",
       "      <td>4839.5</td>\n",
       "      <td>1.978741</td>\n",
       "      <td>-0.149442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.223445</td>\n",
       "      <td>0</td>\n",
       "      <td>1.823382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0               datetime_x  midChangeGroup  futMid       mid  \\\n",
       "0           0  2018-02-01 08:00:18.248               7  4839.5  1.964891   \n",
       "1           1  2018-02-01 08:00:18.248               8  4839.5  1.978741   \n",
       "2           2  2018-02-01 08:00:18.248               8  4839.5  1.978741   \n",
       "3           3  2018-02-01 08:00:18.248               8  4839.5  1.978741   \n",
       "4           4  2018-02-01 08:00:18.249               8  4839.5  1.978741   \n",
       "\n",
       "   arrival_rate  price  size  imbalance  Trade    spread  \n",
       "0      2.148942    0.0   0.0  -0.876897      0  3.477824  \n",
       "1     -0.429102    0.0   0.0  -1.618022      0  1.823382  \n",
       "2      0.069116    0.0   0.0  -1.927718      0  1.823382  \n",
       "3      0.031515    0.0   0.0  -2.089693      0  1.823382  \n",
       "4     -0.149442    0.0   0.0  -2.223445      0  1.823382  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_std = pd.read_csv('merged.csv')\n",
    "df_std.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "OwUmSI6EzCSx"
   },
   "outputs": [],
   "source": [
    "def model_run():\n",
    " \n",
    "    data = DataLoader(\n",
    "        configs['data']['filename'],\n",
    "        configs['data']['train_test_split'],\n",
    "        configs['data']['columns']\n",
    "    )\n",
    "\n",
    "    model = Model()\n",
    "    model.build_model(configs)\n",
    "    x, y = data.get_train_data(\n",
    "        seq_len=configs['data']['sequence_length'],\n",
    "        normalise=configs['data']['normalise']\n",
    "    )\n",
    "\n",
    "    '''\n",
    "        # in-memory training\n",
    "        model.train(\n",
    "            x,\n",
    "            y,\n",
    "            epochs = configs['training']['epochs'],\n",
    "            batch_size = configs['training']['batch_size'],\n",
    "            save_dir = configs['model']['save_dir']\n",
    "        )\n",
    "    '''\n",
    "    x_test, y_test = data.get_test_data(\n",
    "        seq_len=configs['data']['sequence_length'],\n",
    "        normalise=configs['data']['normalise']\n",
    "    )\n",
    "    \n",
    "    # out-of memory generative training\n",
    "    steps_per_epoch = math.ceil((data.len_train - configs['data']['sequence_length']) / configs['training']['batch_size'])\n",
    "    model.train_generator(\n",
    "        data_gen=data.generate_train_batch(\n",
    "            seq_len=configs['data']['sequence_length'],\n",
    "            batch_size=configs['training']['batch_size'],\n",
    "            normalise=configs['data']['normalise']\n",
    "        ),\n",
    "        epochs=configs['training']['epochs'],\n",
    "        batch_size=configs['training']['batch_size'],\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        save_dir=configs['model']['save_dir']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177
    },
    "colab_type": "code",
    "id": "IzRfMQbdzSSV",
    "outputId": "b90e8e88-4428-43b3-9116-ad05ce893da4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 49, 20)            2240      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 49, 20)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 49, 30)            6120      \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 30)                7320      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 15,711\n",
      "Trainable params: 15,711\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[Model] Model Compiled\n",
      "Time taken: 0:00:01.332029\n",
      "[Model] Training Started\n",
      "[Model] 10 epochs, 256 batch size, 5227.0 batches per epoch\n",
      "Epoch 1/10\n",
      "5227/5227 [==============================] - 1927s 369ms/step - loss: 0.4993\n",
      "Epoch 2/10\n",
      "5227/5227 [==============================] - 2136s 409ms/step - loss: 0.3974\n",
      "Epoch 3/10\n",
      "5227/5227 [==============================] - 2124s 406ms/step - loss: 0.3426\n",
      "Epoch 4/10\n",
      "5227/5227 [==============================] - 2368s 453ms/step - loss: 0.2999\n",
      "Epoch 5/10\n",
      "5227/5227 [==============================] - 2190s 419ms/step - loss: 0.2793\n",
      "Epoch 6/10\n",
      "5227/5227 [==============================] - 2232s 427ms/step - loss: 0.2412\n",
      "Epoch 7/10\n",
      "5227/5227 [==============================] - 2203s 422ms/step - loss: 0.2279\n",
      "Epoch 8/10\n",
      "5227/5227 [==============================] - 2229s 426ms/step - loss: 0.1990\n",
      "Epoch 9/10\n",
      "5227/5227 [==============================] - 2200s 421ms/step - loss: 0.1801\n",
      "Epoch 10/10\n",
      "5227/5227 [==============================] - 2181s 417ms/step - loss: 0.1657\n",
      "[Model] Training Completed. Model saved as saved_models/12012019-110735-e10.h5\n",
      "Time taken: 6:03:20.948028\n"
     ]
    }
   ],
   "source": [
    "model = model_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 49, 20)            2240      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 49, 20)            0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 49, 30)            6120      \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 30)                7320      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 15,711\n",
      "Trainable params: 15,711\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[Model] Model Compiled\n",
      "Time taken: 0:00:07.839730\n",
      "[Model] Loading model from file ./saved_models/12012019-110735-e10.h5\n"
     ]
    }
   ],
   "source": [
    "#Loading saved model\n",
    "from keras.models import load_model\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "#To run if not trained the model\n",
    "\n",
    "model = Model()\n",
    "model.build_model(configs)\n",
    "model.load_model('./saved_models/12012019-110735-e10.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model] Predicting Point-by-Point...\n",
      "RMS = 0.1228. #Predictions = 10000\n",
      "[Model] Predicting Point-by-Point...\n",
      "RMS = 0.1119. #Predictions = 10000\n",
      "[Model] Predicting Point-by-Point...\n",
      "RMS = 0.4325. #Predictions = 10000\n"
     ]
    }
   ],
   "source": [
    "#Comparisons of errors \n",
    "def error_cal(pred,y):\n",
    "    rms = sqrt(mean_squared_error(pred,y))\n",
    "    predCount = len(pred)\n",
    "    print('RMS = %.4f. #Predictions = %s' % (rms, predCount))\n",
    "    return rms\n",
    "\n",
    "data_train = DataLoader(configs['data']['filename'],0.8,configs['data']['columns'])\n",
    "data_test = DataLoader(configs['data']['test_filename'],0.1,configs['data']['columns'])\n",
    "\n",
    "#Training error\n",
    "x_train, y_train = data_train.get_train_data(seq_len=configs['data']['sequence_length'],normalise=configs['data']['normalise'])\n",
    "pred_train = model.predict_point_by_point(x_train[10000:20000,:,:])\n",
    "error_train = error_cal(pred_train,y_train[10000:20000])\n",
    "\n",
    "#Cross-validation error \n",
    "x_cv, y_cv = data_train.get_test_data(seq_len=configs['data']['sequence_length'],normalise=configs['data']['normalise'])\n",
    "pred_cv = model.predict_point_by_point(x_cv[:10000,:,:])\n",
    "error_train = error_cal(pred_cv,y_cv[:10000])\n",
    "\n",
    "#Test error\n",
    "x_test, y_test = data_test.get_test_data(seq_len=configs['data']['sequence_length'],normalise=configs['data']['normalise'])\n",
    "pred_test = model.predict_point_by_point(x_test[:10000,:,:])\n",
    "error_test = error_cal(pred_test,y_test[:10000])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 49, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Z7nmV-kk_Gbu"
   },
   "outputs": [],
   "source": [
    "data = DataLoader(\n",
    "        configs['data']['filename'],\n",
    "        configs['data']['train_test_split'],\n",
    "        configs['data']['columns']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "hwbkqhfqI_se"
   },
   "outputs": [],
   "source": [
    "x_test, y_test = data.get_test_data(\n",
    "        seq_len=configs['data']['sequence_length'],\n",
    "        normalise=configs['data']['normalise']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "tR59UrZYJHMJ",
    "outputId": "8a8f43dd-8227-4b77-805c-1564c166c654"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(334501, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "9y58TVNeJJsO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Hyperparameter_optimization.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
